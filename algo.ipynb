{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c985770b",
   "metadata": {},
   "source": [
    "# WIP Replicating AdpQ\n",
    "\n",
    "From [Ghaffari et al 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install huggingface_hub transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6949b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    from huggingface_hub import login\n",
    "    login() # To access gated repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43c0961",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AwqConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460fb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d31c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boiler plate code\n",
    "import glob\n",
    "from IPython.display import Javascript, display\n",
    "import functools\n",
    "from huggingface_hub import snapshot_download\n",
    "import os\n",
    "\n",
    "def notify_when_done(show_popup=True, message=\"✅ Task finished!\"):\n",
    "    \"\"\"\n",
    "    Decorator that notifies (via pop-up and/or sound) when a function finishes running.\n",
    "    \n",
    "    Args:\n",
    "        show_popup (bool): Whether to show a pop-up message.\n",
    "        play_sound (bool): Whether to play a notification sound.\n",
    "        message (str): Message to show in the pop-up.\n",
    "    \"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            error = False\n",
    "            try:\n",
    "                return func(*args, **kwargs)\n",
    "            except Exception as e:\n",
    "                display(Javascript(f'alert(\"❌ An error occurred: {str(e)}\")'))\n",
    "                error = True\n",
    "                raise e\n",
    "            finally:\n",
    "                if show_popup and not error:\n",
    "                    display(Javascript(f'alert(\"{message}\")'))\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# Load Hugging Face token from token.txt if it exists\n",
    "token_folder = glob.glob(\"token.txt\")\n",
    "if token_folder:\n",
    "    with open(token_folder[0], \"r\") as f:\n",
    "        token = f.read().strip()\n",
    "    hf_token = token\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = token\n",
    "\n",
    "@notify_when_done(show_popup=True, message=\"✅ Download complete!\")\n",
    "def download_model(list_of_models, output_dir=\"./\"):\n",
    "    for model_id in list_of_models:\n",
    "\n",
    "        local_folder = os.path.join(output_dir, model_id)\n",
    "\n",
    "        os.makedirs(local_folder, exist_ok=True)\n",
    "\n",
    "        print(f\"Downloading model files for {model_id} to {local_folder}...\")\n",
    "\n",
    "        # --- 2. Download the files ---\n",
    "        snapshot_download(\n",
    "            repo_id=model_id,\n",
    "            local_dir=local_folder,\n",
    "            ignore_patterns=[\"*.bin\", \"*.py\", \"*.md\"],\n",
    "        )\n",
    "\n",
    "        print(\"\\nDownload complete!\")\n",
    "        print(f\"Model files are saved in: {os.path.abspath(local_folder)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358abe0d",
   "metadata": {},
   "source": [
    "## Download weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39898fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_llm = \"hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\"\n",
    "to_quantize_llm = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "download_model([baseline_llm, to_quantize_llm], output_dir=\"./weights\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
